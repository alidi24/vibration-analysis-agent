{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Vibration Analysis Data Science Agent\n\n## AI Agents Intensive Course - Capstone Project\n\n\n**Problem Statement**: Manual exploratory data analysis on industrial vibration data is time-consuming. Data scientists working with condition monitoring systems need to iteratively apply various time-domain and frequency-domain techniques to understand equipment health patterns.\n\n**Solution**: This notebook demonstrates a **Vibration Analysis EDA Agent** - a multi-agent system built with Google's Agent Development Kit (ADK) that helps data scientists interactively explore wind turbine drivetrain vibration data. The agent applies domain-specific signal processing techniques including statistical analysis, spectral analysis, and visualization.\n\n### Key Concepts Demonstrated\n\nThis project demonstrates the following concepts from the course:\n\n1. **Multi-Agent System** - Orchestrator agent delegating to specialized sub-agents\n2. **Custom Tools** - Domain-specific vibration analysis functions\n3. **Sessions & State Management** - Maintaining loaded data and analysis results across conversation turns\n4. **Observability (Logging)** - Tracking agent decisions and tool executions\n\n### Agent Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    Orchestrator Agent                       â”‚\nâ”‚         (Routes requests to specialized agents)             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                      â”‚\n        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n        â–¼             â–¼             â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Time Domain  â”‚ â”‚   Frequency   â”‚ â”‚   Plotting    â”‚\nâ”‚    Agent      â”‚ â”‚ Domain Agent  â”‚ â”‚    Agent      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ â€¢ Statistics  â”‚ â”‚ â€¢ FFT         â”‚ â”‚ â€¢ Time plots  â”‚\nâ”‚ â€¢ RMS         â”‚ â”‚ â€¢ Welch PSD   â”‚ â”‚ â€¢ FFT plots   â”‚\nâ”‚ â€¢ Kurtosis    â”‚ â”‚ â€¢ Spectrogram â”‚ â”‚ â€¢ PSD plots   â”‚\nâ”‚ â€¢ Crest Factorâ”‚ â”‚ â€¢ Envelope    â”‚ â”‚ â€¢ Trend plots â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup and Installation\n\nInstall required packages and configure the environment.","metadata":{}},{"cell_type":"code","source":"# Install Google ADK and dependencies\n!pip install -q google-adk>=1.0.0 numpy pandas scipy matplotlib nest_asyncio","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"âœ… Setup and authentication complete.\")\nexcept Exception as e:\n    print(\n        f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy import signal\nfrom scipy.fft import fft, fftfreq\nfrom scipy.signal import hilbert, welch, spectrogram\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nfrom typing import Optional\nimport json\nimport asyncio\nimport nest_asyncio\n\n# Apply nest_asyncio to allow nested event loops in Jupyter\nnest_asyncio.apply()\n\n# Google ADK imports\nfrom google.adk.agents import Agent\nfrom google.adk.runners import Runner  # Changed from InMemoryRunner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\nprint(\"All packages imported successfully!\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Synthetic Data Generation\n\nGenerate realistic synthetic vibration data from wind turbine drivetrains. The dataset includes:\n- 20 wind turbines\n- 2 measurement points: Main Bearing (MB) and Generator Front-End Bearing (GFEB)\n- Daily measurements for January 2025\n- 1-second waveforms at 1000 Hz sampling rate\n- Operational metadata: rotor speed, generator speed, actual power","metadata":{}},{"cell_type":"code","source":"def generate_vibration_waveform(fs: int = 1000, duration: float = 1.0, \n                                 rotor_rpm: float = 15.0, gen_rpm: float = 1500.0,\n                                 base_amplitude: float = 1.0, noise_level: float = 0.3,\n                                 seed: Optional[int] = None) -> np.ndarray:\n    \"\"\"\n    Generate a synthetic vibration waveform with realistic characteristics.\n    \n    Components:\n    - Shaft rotation harmonics (1X, 2X, 3X)\n    - Bearing characteristic frequencies (simulated)\n    - Random noise\n    \"\"\"\n    if seed is not None:\n        np.random.seed(seed)\n    \n    t = np.linspace(0, duration, int(fs * duration), endpoint=False)\n    \n    # Shaft frequencies\n    f_rotor = rotor_rpm / 60  # Hz\n    f_gen = gen_rpm / 60  # Hz\n    \n    # Build signal with harmonics\n    signal_out = np.zeros_like(t)\n    \n    # Rotor harmonics (1X, 2X, 3X)\n    for harmonic in [1, 2, 3]:\n        amp = base_amplitude / harmonic\n        signal_out += amp * np.sin(2 * np.pi * harmonic * f_rotor * t + np.random.uniform(0, 2*np.pi))\n    \n    # Generator harmonics (scaled down, higher frequency)\n    for harmonic in [1, 2]:\n        amp = base_amplitude * 0.3 / harmonic\n        signal_out += amp * np.sin(2 * np.pi * harmonic * f_gen * t + np.random.uniform(0, 2*np.pi))\n    \n    # Simulated bearing frequencies (BPFO-like)\n    f_bearing = f_rotor * 7.5  # Typical ball pass frequency\n    signal_out += base_amplitude * 0.15 * np.sin(2 * np.pi * f_bearing * t)\n    \n    # Add noise\n    signal_out += noise_level * np.random.randn(len(t))\n    \n    return signal_out\n\n\ndef generate_dataset(n_turbines: int = 20, start_date: str = \"2025-01-01\", \n                     n_days: int = 31, fs: int = 1000) -> pd.DataFrame:\n    \"\"\"\n    Generate complete synthetic dataset for wind turbine vibration analysis.\n    \"\"\"\n    measurement_points = ['MB', 'GFEB']  # Main Bearing, Generator Front-End Bearing\n    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n    \n    records = []\n    \n    for turbine_id in range(1, n_turbines + 1):\n        # Each turbine has slightly different baseline characteristics\n        turbine_base_amp = 0.8 + 0.4 * np.random.random()\n        \n        for day_offset in range(n_days):\n            date = start + timedelta(days=day_offset)\n            \n            # Operational conditions vary with wind/time\n            rotor_rpm = 10 + 10 * np.random.random()  # 10-20 RPM typical\n            gen_rpm = rotor_rpm * 100  # Gearbox ratio ~100:1\n            power_kw = (rotor_rpm / 20) ** 3 * 2000 * (0.8 + 0.2 * np.random.random())  # Cubic relation\n            \n            for mp in measurement_points:\n                # Different characteristics per measurement point\n                if mp == 'MB':\n                    amp_factor = 1.0\n                    noise_factor = 0.3\n                else:  # GFEB - typically higher frequency content\n                    amp_factor = 0.7\n                    noise_factor = 0.4\n                \n                seed = turbine_id * 10000 + day_offset * 100 + (0 if mp == 'MB' else 1)\n                waveform = generate_vibration_waveform(\n                    fs=fs,\n                    rotor_rpm=rotor_rpm,\n                    gen_rpm=gen_rpm,\n                    base_amplitude=turbine_base_amp * amp_factor,\n                    noise_level=noise_factor,\n                    seed=seed\n                )\n                \n                records.append({\n                    'turbine_id': f'WT{turbine_id:02d}',\n                    'date': date.strftime(\"%Y-%m-%d\"),\n                    'measurement_point': mp,\n                    'rotor_rpm': round(rotor_rpm, 2),\n                    'generator_rpm': round(gen_rpm, 2),\n                    'power_kw': round(power_kw, 2),\n                    'fs': fs,\n                    'waveform': waveform.tolist()\n                })\n    \n    return pd.DataFrame(records)\n\n\n# Generate the dataset\nprint(\"Generating synthetic vibration dataset...\")\ndf_vibration = generate_dataset(n_turbines=20, n_days=31)\nprint(f\"Dataset shape: {df_vibration.shape}\")\nprint(f\"Columns: {df_vibration.columns.tolist()}\")\nprint(f\"\\nSample record (without waveform):\")\nprint(df_vibration.drop(columns=['waveform']).head())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Analysis Tool Functions\n\nDefine the domain-specific tools that our agents will use for vibration analysis.","metadata":{}},{"cell_type":"code","source":"# Global state to store loaded data and results\nSTATE = {\n    'dataset': df_vibration,\n    'current_waveform': None,\n    'current_metadata': None,\n    'analysis_results': {},\n    'fs': 1000\n}\n\n\n# ============== Data Loading Tools ==============\n\ndef list_available_data() -> dict:\n    \"\"\"\n    List available turbines, measurement points, and date range in the dataset.\n    Use this to understand what data is available for analysis.\n    \"\"\"\n    df = STATE['dataset']\n    return {\n        'turbines': sorted(df['turbine_id'].unique().tolist()),\n        'measurement_points': df['measurement_point'].unique().tolist(),\n        'date_range': {'start': df['date'].min(), 'end': df['date'].max()},\n        'total_records': len(df)\n    }\n\n\ndef load_waveform(turbine_id: str, measurement_point: str, date: str) -> dict:\n    \"\"\"\n    Load a specific vibration waveform for analysis.\n    \n    Args:\n        turbine_id: Turbine identifier (e.g., 'WT01')\n        measurement_point: 'MB' (Main Bearing) or 'GFEB' (Generator Front-End Bearing)\n        date: Date string in YYYY-MM-DD format\n    \n    Returns:\n        Dictionary with waveform info and operational metadata\n    \"\"\"\n    df = STATE['dataset']\n    mask = (df['turbine_id'] == turbine_id) & \\\n           (df['measurement_point'] == measurement_point) & \\\n           (df['date'] == date)\n    \n    if mask.sum() == 0:\n        return {'error': f'No data found for {turbine_id}, {measurement_point}, {date}'}\n    \n    record = df[mask].iloc[0]\n    waveform = np.array(record['waveform'])\n    \n    STATE['current_waveform'] = waveform\n    STATE['current_metadata'] = {\n        'turbine_id': turbine_id,\n        'measurement_point': measurement_point,\n        'date': date,\n        'rotor_rpm': record['rotor_rpm'],\n        'generator_rpm': record['generator_rpm'],\n        'power_kw': record['power_kw'],\n        'fs': record['fs']\n    }\n    STATE['fs'] = record['fs']\n    STATE['analysis_results'] = {}  # Clear previous results\n    \n    return {\n        'status': 'success',\n        'message': f'Loaded waveform for {turbine_id} - {measurement_point} on {date}',\n        'samples': len(waveform),\n        'duration_sec': len(waveform) / record['fs'],\n        'operational_data': {\n            'rotor_rpm': record['rotor_rpm'],\n            'generator_rpm': record['generator_rpm'],\n            'power_kw': record['power_kw']\n        }\n    }","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============== Time Domain Analysis Tools ==============\n\ndef compute_time_domain_statistics() -> dict:\n    \"\"\"\n    Compute comprehensive time-domain statistics for the loaded waveform.\n    \n    Returns:\n        Dictionary containing: mean, std, rms, peak, peak_to_peak, \n        crest_factor, kurtosis, skewness\n    \"\"\"\n    if STATE['current_waveform'] is None:\n        return {'error': 'No waveform loaded. Use load_waveform first.'}\n    \n    x = STATE['current_waveform']\n    \n    # Basic statistics\n    mean_val = float(np.mean(x))\n    std_val = float(np.std(x))\n    rms_val = float(np.sqrt(np.mean(x**2)))\n    \n    # Peak values\n    peak_val = float(np.max(np.abs(x)))\n    peak_to_peak = float(np.max(x) - np.min(x))\n    \n    # Crest factor (peak / RMS)\n    crest_factor = float(peak_val / rms_val) if rms_val > 0 else 0\n    \n    # Higher-order statistics\n    from scipy.stats import kurtosis, skew\n    kurtosis_val = float(kurtosis(x))\n    skewness_val = float(skew(x))\n    \n    results = {\n        'mean': round(mean_val, 6),\n        'std': round(std_val, 6),\n        'rms': round(rms_val, 6),\n        'peak': round(peak_val, 6),\n        'peak_to_peak': round(peak_to_peak, 6),\n        'crest_factor': round(crest_factor, 4),\n        'kurtosis': round(kurtosis_val, 4),\n        'skewness': round(skewness_val, 4)\n    }\n    \n    STATE['analysis_results']['time_domain_stats'] = results\n    return results\n\n\ndef compute_rms_trend(turbine_id: str, measurement_point: str, \n                      start_date: str, end_date: str) -> dict:\n    \"\"\"\n    Compute RMS trend over a date range for a specific turbine and measurement point.\n    \n    Args:\n        turbine_id: Turbine identifier (e.g., 'WT01')\n        measurement_point: 'MB' or 'GFEB'\n        start_date: Start date (YYYY-MM-DD)\n        end_date: End date (YYYY-MM-DD)\n    \n    Returns:\n        Dictionary with dates and corresponding RMS values\n    \"\"\"\n    df = STATE['dataset']\n    mask = (df['turbine_id'] == turbine_id) & \\\n           (df['measurement_point'] == measurement_point) & \\\n           (df['date'] >= start_date) & \\\n           (df['date'] <= end_date)\n    \n    filtered = df[mask].sort_values('date')\n    \n    if len(filtered) == 0:\n        return {'error': 'No data found for the specified parameters'}\n    \n    dates = []\n    rms_values = []\n    \n    for _, row in filtered.iterrows():\n        waveform = np.array(row['waveform'])\n        rms = float(np.sqrt(np.mean(waveform**2)))\n        dates.append(row['date'])\n        rms_values.append(round(rms, 6))\n    \n    results = {\n        'turbine_id': turbine_id,\n        'measurement_point': measurement_point,\n        'dates': dates,\n        'rms_values': rms_values,\n        'mean_rms': round(np.mean(rms_values), 6),\n        'std_rms': round(np.std(rms_values), 6),\n        'trend_direction': 'increasing' if rms_values[-1] > rms_values[0] else 'decreasing'\n    }\n    \n    STATE['analysis_results']['rms_trend'] = results\n    return results","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============== Frequency Domain Analysis Tools ==============\n\ndef compute_fft_spectrum() -> dict:\n    \"\"\"\n    Compute FFT spectrum of the loaded waveform.\n    \n    Returns:\n        Dictionary with frequency array, amplitude spectrum, and dominant frequencies\n    \"\"\"\n    if STATE['current_waveform'] is None:\n        return {'error': 'No waveform loaded. Use load_waveform first.'}\n    \n    x = STATE['current_waveform']\n    fs = STATE['fs']\n    n = len(x)\n    \n    # Compute FFT\n    fft_vals = fft(x)\n    freqs = fftfreq(n, 1/fs)\n    \n    # Take positive frequencies only\n    pos_mask = freqs >= 0\n    freqs_pos = freqs[pos_mask]\n    amplitude = np.abs(fft_vals[pos_mask]) * 2 / n\n    \n    # Find dominant frequencies (peaks)\n    from scipy.signal import find_peaks\n    peaks, _ = find_peaks(amplitude, height=np.max(amplitude) * 0.1)\n    dominant_freqs = [(float(freqs_pos[p]), float(amplitude[p])) for p in peaks[:10]]\n    dominant_freqs.sort(key=lambda x: x[1], reverse=True)\n    \n    results = {\n        'frequencies': freqs_pos.tolist(),\n        'amplitude': amplitude.tolist(),\n        'dominant_frequencies': [{'freq_hz': f, 'amplitude': a} for f, a in dominant_freqs[:5]],\n        'freq_resolution': float(fs / n)\n    }\n    \n    STATE['analysis_results']['fft'] = results\n    return {\n        'status': 'success',\n        'dominant_frequencies': results['dominant_frequencies'],\n        'freq_resolution': results['freq_resolution'],\n        'message': 'FFT computed. Use plotting agent to visualize.'\n    }\n\n\ndef compute_welch_psd(nperseg: int = 256) -> dict:\n    \"\"\"\n    Compute Power Spectral Density using Welch's method.\n    \n    Args:\n        nperseg: Length of each segment for Welch's method\n    \n    Returns:\n        Dictionary with frequencies and PSD values\n    \"\"\"\n    if STATE['current_waveform'] is None:\n        return {'error': 'No waveform loaded. Use load_waveform first.'}\n    \n    x = STATE['current_waveform']\n    fs = STATE['fs']\n    \n    freqs, psd = welch(x, fs=fs, nperseg=min(nperseg, len(x)//2))\n    \n    # Find peak frequency\n    peak_idx = np.argmax(psd)\n    \n    results = {\n        'frequencies': freqs.tolist(),\n        'psd': psd.tolist(),\n        'peak_frequency_hz': float(freqs[peak_idx]),\n        'peak_psd': float(psd[peak_idx]),\n        'total_power': float(np.trapz(psd, freqs))\n    }\n    \n    STATE['analysis_results']['welch'] = results\n    return {\n        'status': 'success',\n        'peak_frequency_hz': results['peak_frequency_hz'],\n        'total_power': round(results['total_power'], 6),\n        'message': 'Welch PSD computed. Use plotting agent to visualize.'\n    }\n\n\ndef compute_spectrogram(nperseg: int = 128) -> dict:\n    \"\"\"\n    Compute spectrogram (time-frequency representation) of the loaded waveform.\n    \n    Args:\n        nperseg: Length of each segment\n    \n    Returns:\n        Dictionary with time, frequency, and spectrogram matrix info\n    \"\"\"\n    if STATE['current_waveform'] is None:\n        return {'error': 'No waveform loaded. Use load_waveform first.'}\n    \n    x = STATE['current_waveform']\n    fs = STATE['fs']\n    \n    f, t, Sxx = spectrogram(x, fs=fs, nperseg=min(nperseg, len(x)//4))\n    \n    results = {\n        'frequencies': f.tolist(),\n        'times': t.tolist(),\n        'spectrogram': Sxx.tolist(),\n        'freq_bins': len(f),\n        'time_bins': len(t)\n    }\n    \n    STATE['analysis_results']['spectrogram'] = results\n    return {\n        'status': 'success',\n        'freq_bins': len(f),\n        'time_bins': len(t),\n        'message': 'Spectrogram computed. Use plotting agent to visualize.'\n    }\n\n\ndef compute_envelope_spectrum() -> dict:\n    \"\"\"\n    Compute envelope spectrum using Hilbert transform.\n    Useful for detecting bearing fault frequencies.\n    \n    Returns:\n        Dictionary with envelope spectrum data\n    \"\"\"\n    if STATE['current_waveform'] is None:\n        return {'error': 'No waveform loaded. Use load_waveform first.'}\n    \n    x = STATE['current_waveform']\n    fs = STATE['fs']\n    \n    # Compute analytic signal using Hilbert transform\n    analytic_signal = hilbert(x)\n    envelope = np.abs(analytic_signal)\n    \n    # Remove DC component from envelope\n    envelope = envelope - np.mean(envelope)\n    \n    # Compute FFT of envelope\n    n = len(envelope)\n    fft_env = fft(envelope)\n    freqs = fftfreq(n, 1/fs)\n    \n    pos_mask = freqs >= 0\n    freqs_pos = freqs[pos_mask]\n    amplitude = np.abs(fft_env[pos_mask]) * 2 / n\n    \n    # Find peaks in envelope spectrum\n    from scipy.signal import find_peaks\n    peaks, _ = find_peaks(amplitude, height=np.max(amplitude) * 0.1)\n    dominant_freqs = [(float(freqs_pos[p]), float(amplitude[p])) for p in peaks[:10]]\n    dominant_freqs.sort(key=lambda x: x[1], reverse=True)\n    \n    results = {\n        'frequencies': freqs_pos.tolist(),\n        'envelope_amplitude': amplitude.tolist(),\n        'envelope_time': envelope.tolist(),\n        'dominant_frequencies': [{'freq_hz': f, 'amplitude': a} for f, a in dominant_freqs[:5]]\n    }\n    \n    STATE['analysis_results']['envelope'] = results\n    return {\n        'status': 'success',\n        'dominant_frequencies': results['dominant_frequencies'],\n        'message': 'Envelope spectrum computed. Use plotting agent to visualize.'\n    }","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============== Plotting Tools ==============\n\ndef plot_time_waveform() -> dict:\n    \"\"\"\n    Plot the time-domain waveform of the loaded signal.\n    \"\"\"\n    if STATE['current_waveform'] is None:\n        return {'error': 'No waveform loaded. Use load_waveform first.'}\n    \n    x = STATE['current_waveform']\n    fs = STATE['fs']\n    t = np.arange(len(x)) / fs\n    meta = STATE['current_metadata']\n    \n    plt.figure(figsize=(12, 4))\n    plt.plot(t, x, 'b-', linewidth=0.5)\n    plt.xlabel('Time (s)')\n    plt.ylabel('Amplitude')\n    plt.title(f\"Time Waveform - {meta['turbine_id']} | {meta['measurement_point']} | {meta['date']}\")\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n    \n    return {'status': 'success', 'message': 'Time waveform plot generated'}\n\n\ndef plot_fft_spectrum() -> dict:\n    \"\"\"\n    Plot the FFT amplitude spectrum. Must compute FFT first.\n    \"\"\"\n    if 'fft' not in STATE['analysis_results']:\n        return {'error': 'FFT not computed. Run compute_fft_spectrum first.'}\n    \n    results = STATE['analysis_results']['fft']\n    meta = STATE['current_metadata']\n    \n    freqs = np.array(results['frequencies'])\n    amplitude = np.array(results['amplitude'])\n    \n    plt.figure(figsize=(12, 4))\n    plt.plot(freqs, amplitude, 'b-', linewidth=0.5)\n    plt.xlabel('Frequency (Hz)')\n    plt.ylabel('Amplitude')\n    plt.title(f\"FFT Spectrum - {meta['turbine_id']} | {meta['measurement_point']} | {meta['date']}\")\n    plt.xlim([0, STATE['fs']/2])\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n    \n    return {'status': 'success', 'message': 'FFT spectrum plot generated'}\n\n\ndef plot_welch_psd() -> dict:\n    \"\"\"\n    Plot the Power Spectral Density (Welch). Must compute Welch PSD first.\n    \"\"\"\n    if 'welch' not in STATE['analysis_results']:\n        return {'error': 'Welch PSD not computed. Run compute_welch_psd first.'}\n    \n    results = STATE['analysis_results']['welch']\n    meta = STATE['current_metadata']\n    \n    freqs = np.array(results['frequencies'])\n    psd = np.array(results['psd'])\n    \n    plt.figure(figsize=(12, 4))\n    plt.semilogy(freqs, psd, 'b-', linewidth=1)\n    plt.xlabel('Frequency (Hz)')\n    plt.ylabel('PSD')\n    plt.title(f\"Power Spectral Density (Welch) - {meta['turbine_id']} | {meta['measurement_point']} | {meta['date']}\")\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n    \n    return {'status': 'success', 'message': 'Welch PSD plot generated'}\n\n\ndef plot_spectrogram() -> dict:\n    \"\"\"\n    Plot the spectrogram. Must compute spectrogram first.\n    \"\"\"\n    if 'spectrogram' not in STATE['analysis_results']:\n        return {'error': 'Spectrogram not computed. Run compute_spectrogram first.'}\n    \n    results = STATE['analysis_results']['spectrogram']\n    meta = STATE['current_metadata']\n    \n    f = np.array(results['frequencies'])\n    t = np.array(results['times'])\n    Sxx = np.array(results['spectrogram'])\n    \n    plt.figure(figsize=(12, 5))\n    plt.pcolormesh(t, f, 10 * np.log10(Sxx + 1e-10), shading='gouraud', cmap='viridis')\n    plt.colorbar(label='Power/Frequency (dB/Hz)')\n    plt.xlabel('Time (s)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title(f\"Spectrogram - {meta['turbine_id']} | {meta['measurement_point']} | {meta['date']}\")\n    plt.tight_layout()\n    plt.show()\n    \n    return {'status': 'success', 'message': 'Spectrogram plot generated'}\n\n\ndef plot_envelope_spectrum() -> dict:\n    \"\"\"\n    Plot the envelope spectrum. Must compute envelope spectrum first.\n    \"\"\"\n    if 'envelope' not in STATE['analysis_results']:\n        return {'error': 'Envelope spectrum not computed. Run compute_envelope_spectrum first.'}\n    \n    results = STATE['analysis_results']['envelope']\n    meta = STATE['current_metadata']\n    \n    freqs = np.array(results['frequencies'])\n    amplitude = np.array(results['envelope_amplitude'])\n    \n    plt.figure(figsize=(12, 4))\n    plt.plot(freqs, amplitude, 'b-', linewidth=0.5)\n    plt.xlabel('Frequency (Hz)')\n    plt.ylabel('Envelope Amplitude')\n    plt.title(f\"Envelope Spectrum - {meta['turbine_id']} | {meta['measurement_point']} | {meta['date']}\")\n    plt.xlim([0, 100])  # Focus on lower frequencies for bearing analysis\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n    \n    return {'status': 'success', 'message': 'Envelope spectrum plot generated'}\n\n\ndef plot_rms_trend() -> dict:\n    \"\"\"\n    Plot the RMS trend over time. Must compute RMS trend first.\n    \"\"\"\n    if 'rms_trend' not in STATE['analysis_results']:\n        return {'error': 'RMS trend not computed. Run compute_rms_trend first.'}\n    \n    results = STATE['analysis_results']['rms_trend']\n    \n    dates = pd.to_datetime(results['dates'])\n    rms_values = results['rms_values']\n    \n    plt.figure(figsize=(12, 4))\n    plt.plot(dates, rms_values, 'b-o', markersize=4)\n    plt.axhline(y=results['mean_rms'], color='r', linestyle='--', label=f\"Mean: {results['mean_rms']:.4f}\")\n    plt.fill_between(dates, \n                     results['mean_rms'] - results['std_rms'], \n                     results['mean_rms'] + results['std_rms'], \n                     alpha=0.2, color='red', label='Â±1 Std')\n    plt.xlabel('Date')\n    plt.ylabel('RMS')\n    plt.title(f\"RMS Trend - {results['turbine_id']} | {results['measurement_point']}\")\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n    \n    return {'status': 'success', 'message': 'RMS trend plot generated'}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Agent Definitions\n\nDefine the multi-agent system using Google ADK.","metadata":{}},{"cell_type":"code","source":"# Time Domain Analysis Agent\ntime_domain_agent = Agent(\n    name=\"time_domain_agent\",\n    model=\"gemini-2.0-flash\",\n    description=\"Specialist agent for time-domain vibration analysis including statistical metrics and energy-based parameters.\",\n    instruction=\"\"\"You are a time-domain vibration analysis specialist. Your role is to:\n    \n1. Compute statistical parameters: mean, standard deviation, RMS, peak values\n2. Calculate energy-based metrics: crest factor, kurtosis, skewness\n3. Analyze RMS trends over time to detect degradation patterns\n\nWhen asked to analyze a signal:\n- First ensure a waveform is loaded using load_waveform\n- Use compute_time_domain_statistics for single waveform analysis\n- Use compute_rms_trend for temporal trend analysis\n\nProvide clear interpretations of the results:\n- High kurtosis (>3) may indicate impulsive events or bearing damage\n- High crest factor indicates presence of peaks/impacts\n- RMS trend increases may indicate developing faults\n\nAlways explain what each metric means in the context of vibration analysis.\"\"\",\n    tools=[load_waveform, list_available_data, compute_time_domain_statistics, compute_rms_trend]\n)\n\nprint(\"Time Domain Agent created successfully!\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Frequency Domain Analysis Agent\nfrequency_domain_agent = Agent(\n    name=\"frequency_domain_agent\",\n    model=\"gemini-2.0-flash\",\n    description=\"Specialist agent for frequency-domain vibration analysis including spectral and envelope analysis.\",\n    instruction=\"\"\"You are a frequency-domain vibration analysis specialist. Your role is to:\n\n1. Compute FFT spectrum to identify dominant frequencies\n2. Calculate Power Spectral Density using Welch's method for smoother spectral estimates\n3. Generate spectrograms for time-frequency analysis\n4. Perform envelope analysis using Hilbert transform for bearing fault detection\n\nWhen analyzing frequency content:\n- Use compute_fft_spectrum for basic spectral analysis\n- Use compute_welch_psd for energy distribution analysis\n- Use compute_spectrogram for time-varying frequency content\n- Use compute_envelope_spectrum for bearing fault frequency identification\n\nKey frequency relationships to consider:\n- Shaft rotation frequency = RPM / 60\n- Harmonics (2X, 3X, etc.) indicate misalignment or looseness\n- Bearing frequencies typically appear in envelope spectrum\n\nAlways relate dominant frequencies to the operational speed when interpreting results.\"\"\",\n    tools=[load_waveform, list_available_data, compute_fft_spectrum, compute_welch_psd, \n           compute_spectrogram, compute_envelope_spectrum]\n)\n\nprint(\"Frequency Domain Agent created successfully!\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting Agent\nplotting_agent = Agent(\n    name=\"plotting_agent\",\n    model=\"gemini-2.0-flash\",\n    description=\"Specialist agent for creating visualizations of vibration analysis results.\",\n    instruction=\"\"\"You are a visualization specialist for vibration data. Your role is to create clear and informative plots.\n\nAvailable plotting functions:\n- plot_time_waveform: Show the raw time-domain signal\n- plot_fft_spectrum: Display FFT amplitude spectrum (requires FFT computation first)\n- plot_welch_psd: Show Power Spectral Density plot (requires Welch computation first)\n- plot_spectrogram: Display time-frequency representation (requires spectrogram computation first)\n- plot_envelope_spectrum: Show envelope spectrum for bearing analysis (requires envelope computation first)\n- plot_rms_trend: Display RMS trend over time (requires RMS trend computation first)\n\nImportant notes:\n- Ensure the required analysis has been performed before attempting to plot\n- If a plot fails because analysis is missing, inform the user which analysis needs to be done first\n- For comprehensive analysis, recommend plotting multiple views of the data\n\nWhen asked to visualize, create the appropriate plots and describe what they show.\"\"\",\n    tools=[plot_time_waveform, plot_fft_spectrum, plot_welch_psd, \n           plot_spectrogram, plot_envelope_spectrum, plot_rms_trend]\n)\n\nprint(\"Plotting Agent created successfully!\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Root Orchestrator Agent\norchestrator_agent = Agent(\n    name=\"vibration_analysis_orchestrator\",\n    model=\"gemini-2.0-flash\",\n    description=\"Main orchestrator for vibration analysis tasks, delegating to specialized sub-agents.\",\n    instruction=\"\"\"You are the main orchestrator for a vibration analysis system for wind turbine drivetrains.\n    \nYou coordinate three specialist agents:\n1. **time_domain_agent**: For statistical analysis, RMS computation, kurtosis, crest factor, and trend analysis\n2. **frequency_domain_agent**: For FFT, PSD, spectrogram, and envelope spectrum analysis\n3. **plotting_agent**: For creating visualizations of any analysis results\n\nYour workflow:\n1. Understand the user's analysis request\n2. Delegate to the appropriate specialist agent(s)\n3. For visualizations, ensure the required analysis is done first, then delegate to plotting_agent\n4. Synthesize results and provide clear explanations\n\nAvailable data:\n- 20 wind turbines (WT01-WT20)\n- 2 measurement points: MB (Main Bearing), GFEB (Generator Front-End Bearing)\n- Date range: January 2025\n- Operational data: rotor RPM, generator RPM, power (kW)\n\nWhen users ask general questions about the data or what's available, use the list_available_data tool.\nFor any analysis, first load the appropriate waveform using load_waveform.\n\nGuide users through a logical analysis workflow and explain the significance of findings.\"\"\",\n    tools=[list_available_data, load_waveform],\n    sub_agents=[time_domain_agent, frequency_domain_agent, plotting_agent]\n)\n\nprint(\"Orchestrator Agent created successfully!\")\nprint(\"\\nMulti-agent system ready with:\")\nprint(\"  - Orchestrator (root agent)\")\nprint(\"  - Time Domain Agent\")\nprint(\"  - Frequency Domain Agent\")\nprint(\"  - Plotting Agent\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Session Setup and Runner\n\nConfigure the session service for state management and create the runner.","metadata":{}},{"cell_type":"code","source":"# Session configuration\nAPP_NAME = \"vibration_analysis\"\nUSER_ID = \"data_scientist_01\"\nSESSION_ID = \"session_001\"\n\n# Create session service for state management\nsession_service = InMemorySessionService()\n\n# Create session first\nsession = await session_service.create_session(\n    app_name=APP_NAME,\n    user_id=USER_ID,\n    session_id=SESSION_ID\n)\n\n# Create runner with the orchestrator agent\nrunner = Runner(\n    agent=orchestrator_agent,\n    app_name=APP_NAME,\n    session_service=session_service\n)\n\nprint(f\"Session initialized:\")\nprint(f\"  App: {APP_NAME}\")\nprint(f\"  User: {USER_ID}\")\nprint(f\"  Session: {SESSION_ID}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"async def chat(user_message: str) -> str:\n    \"\"\"\n    Send a message to the agent and get a response.\n    Includes logging for observability.\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"USER: {user_message}\")\n    print(f\"{'='*60}\")\n    \n    # Create the user message content\n    content = types.Content(\n        role=\"user\",\n        parts=[types.Part.from_text(text=user_message)]\n    )\n    \n    final_response = \"\"\n    \n    # Run the agent and collect responses\n    async for event in runner.run_async(\n        user_id=USER_ID,\n        session_id=SESSION_ID,\n        new_message=content\n    ):\n        # Log tool calls for observability\n        if event.get_function_calls():\n            for fc in event.get_function_calls():\n                print(f\"  [TOOL CALL] {fc.name}({fc.args})\")\n        \n        # Collect final text response\n        if event.is_final_response() and event.content and event.content.parts:\n            for part in event.content.parts:\n                if hasattr(part, 'text') and part.text:\n                    final_response += part.text\n    \n    print(f\"\\nAGENT: {final_response}\")\n    return final_response\n\n\ndef run_chat(message: str) -> str:\n    \"\"\"Synchronous wrapper for the chat function.\"\"\"\n    return asyncio.get_event_loop().run_until_complete(chat(message))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Interactive Demo\n\nLet's demonstrate the agent system with example queries.","metadata":{}},{"cell_type":"code","source":"# Query 1: Explore available data\nawait chat(\"What data is available in the system? Show me the turbines, measurement points, and date range.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Query 2: Load and analyze a specific waveform\nawait chat(\"Load the vibration data for turbine WT05, Main Bearing, on January 15, 2025 and compute time-domain statistics.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Query 3: Visualize the time waveform\nawait chat(\"Plot the time waveform for the loaded signal.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Query 4: Frequency analysis\nawait chat(\"Perform FFT analysis on the current signal and show me the dominant frequencies.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Query 5: Plot FFT spectrum\nawait chat(\"Plot the FFT spectrum.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Query 6: Welch PSD analysis\nawait chat(\"Calculate and plot the Power Spectral Density using Welch's method.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Query 7: Envelope spectrum for bearing analysis\nawait chat(\"Compute the envelope spectrum using Hilbert transform and plot it. This is useful for bearing fault detection.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Query 8: RMS trend analysis\nawait chat(\"Calculate the RMS trend for turbine WT05, Main Bearing, for the entire month of January 2025 and plot it.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Query 9: Compare different measurement points\nawait chat(\"Load data for turbine WT05, Generator Front-End Bearing (GFEB), same date (January 15, 2025) and perform time-domain analysis. How does it compare to the Main Bearing?\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Query 10: Spectrogram analysis\nawait chat(\"Generate a spectrogram for the current signal to see the time-frequency characteristics.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Custom Analysis Session\n\nThis section allows for interactive exploration. Modify the queries below to explore the data.","metadata":{}},{"cell_type":"code","source":"# Custom query - modify as needed\nawait chat(\"Give me a comprehensive analysis of turbine WT10 Main Bearing on January 20, 2025. Include time-domain stats, FFT, and plots.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Project Summary and Value Articulation\n\n### What This Agent Does\n\nThe **Vibration Analysis Data Science Agent** is a multi-agent system that assists data scientists in performing exploratory data analysis on industrial vibration data from wind turbine drivetrains. It provides:\n\n1. **Natural Language Interface**: Query the data and request analyses using conversational language instead of writing code\n2. **Automated Workflow Orchestration**: The orchestrator intelligently routes requests to specialized agents\n3. **Domain-Specific Analysis**: Built-in signal processing tools tailored for vibration analysis\n4. **Interactive Visualization**: Generate plots on demand to understand data patterns\n\n### Key Concepts Demonstrated\n\n| Concept | Implementation |\n|---------|---------------|\n| **Multi-Agent System** | Root orchestrator delegates to time_domain_agent, frequency_domain_agent, and plotting_agent |\n| **Custom Tools** | 15+ domain-specific functions for vibration analysis (RMS, FFT, Welch, Envelope, etc.) |\n| **Sessions & State** | InMemorySessionService maintains conversation context and loaded data across turns |\n| **Observability** | Tool call logging shows agent decisions and execution flow |\n\n### Value Proposition\n\n**Time Savings**: Instead of writing repetitive analysis code, data scientists can:\n- Load and explore data with simple queries\n- Request complex analyses in natural language\n- Generate visualizations without matplotlib boilerplate\n- Compare different signals and measurement points easily\n\n**Estimated Impact**: This agent can reduce initial data exploration time by **2-4 hours per analysis session** by eliminating the need to write custom scripts for common vibration analysis tasks.\n\n### Future Enhancements\n\n1. **Anomaly Detection Agent**: Add ML-based fault detection capabilities\n2. **Report Generation**: Automatically compile analysis results into reports\n3. **Real-time Data Integration**: Connect to live sensor data streams\n\n---\n\n### Technical Stack\n\n- **Framework**: Google Agent Development Kit (ADK)\n- **Model**: Gemini 2.0 Flash\n- **Signal Processing**: NumPy, SciPy\n- **Visualization**: Matplotlib\n- **Data Handling**: Pandas\n\n---\n\n*This notebook was developed as a capstone project for the Google AI Agents Intensive Course (November 2025).*","metadata":{}}]}